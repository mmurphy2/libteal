#!/bin/dash
#
# Downloads one or more files from a single server using curl(1). Download
# progress information is written to a temporary directory as the operation
# proceeds.
#
# Copyright 2022 Coastal Carolina University
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the “Software”), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.

# TODO refactoring in progress: not currently working

whatami=$(readlink -e "$0")
whereami=$(dirname "${whatami}")


usage() {
    cat << EOF
$0 [options] [-- curl_options --] <proto://host> <output_base> \\
             <remote_path> <local_filename> \\
             [[<remote_path> <local_filename>] ...]

Options:
    -e | --enable-config
        Enable reading the default curl configuration file(s). These are
        normally disabled, since the default configuration file locations
        are per-user instead of systemwide (see the man page for curl(1)).
        Providing this option suppresses the -q or --disable option, but
        later specifying -q or --disable in the curl_options will still
        prevent default configuration files from being loaded.
    -h | --help
        Show this help message and exit.
    -s <dir> | --status <dir>
        Use the specified directory for status files. Otherwise, a temporary
        directory is created with mktemp(1).
    -v | --verbose
        Display generated curl configuration on standard error.

Any option supported by curl(1) may be passed by surrounding the curl
options with two dashes (--) separated by spaces.

This program downloads one or more files from a single server, saving them
according to the specified <local_filename> in the <output_base> directory.
The base URL of the server is specified using <proto://host>. Each
<remote_path> is appended to the base directory to obtain the remote URL.
At the time of program invocation, <output_base> must already exist and be
writable by the program user.

Upon starting the operation, the status directory path is printed on
standard output. The status directory is organized in a hierarchy with
individual download data directories numbered starting from 0. At the top
level, status information consists of:

 base_url             The base URL from which files are downloaded
 current_transfer     The number of the current transfer
 progress.log         Raw progress output from curl
 result               Overall exit status, available when finished
 status_codes         Exit and HTTP response codes for each transfer
 total_transfers      The total number of files to be transferred

Each individual file transfer has its own status directory containing
information about the ongoing download:

 destination          Local path to which the download will be saved
 http_code            Response code for HTTP transfers
 percent              Integer percentage of the download completed
 remain               Time remaining in seconds
 result               Per-file transfer status
 speed                Current transfer speed in bytes per second
 total                Total file size in bytes
 transferred          Total number of bytes downloaded so far
 url                  URL from which the transfer is made

Note that percent, remain, and total require the server to provide a correct
content-length (or equivalent) at the start of the download. These values
therefore might not be available from some servers.
EOF
}


# signal_curl <signal>
#
# Signals the curl process.
signal_curl() {
    # We can only send a signal to curl if it is running. The curl process is running if curlpid is non-empty,
    # the process with PID curlpid is found in the process table, and we are the parent of that process. This
    # extra parent check avoids an unlikely but possible condition where curl dies while this code's main loop
    # is asleep, and the PID number gets reused in the meantime.
    if [ -n "${curlpid}" ]; then
        local ppid=$(ps -p "${curlpid}" -o ppid=)
        if [ -n "${ppid}" ]; then
            if [ "${ppid}" -eq "$$" ]; then
                kill -s "$1" "${curlpid}"
            fi
        fi
    fi
}


# Invokes the download_from_server.awk script to process the contents of the progress log. Since curl uses
# carriage returns to overwrite the current transfer status line, we first convert these into newlines to let
# awk handle them as individual records.
update_progress() {
    cat "${status_output}/progress.log" | tr '\r' '\n' | \
        awk -f "${whereami}/download_from_server.awk" -v status_root="${status_output}"
}


# Signal handling wrappers
sighup() {
    # curl seems to ignore SIGHUP by default, so send SIGINT instead
    signal_curl INT
}

sigint() {
    signal_curl INT
}

sigquit() {
    signal_curl QUIT
}

sigterm() {
    signal_curl TERM
}

sigcont() {
    signal_curl CONT
}

sigtstop() {
    signal_curl TSTP
}


status_output=
proxy=
enable_config="-q"
verbose=
while [ $# -gt 0 ]; do
    case "$1" in
        -e|--enable-config)
            enable_config=
            shift
        ;;
        -h|--help)
            usage
            exit 0
        ;;
        -s|--status)
            status_output="$2"
            shift 2
        ;;
        -v|--verbose)
            verbose="y"
            shift
        ;;
        *)
            break
        ;;
    esac
done


# Generate the curl configuration by appending any curl options
curl_conf="# generated curl configuration"
if [ x"$1" = x"--" ]; then
    shift
    while [ $# -gt 0 -a "x$1" != "--" ]; do
        if echo "$1" | grep -q '^-'; then
            # We have an option: start a new line and append the option
            curl_conf=$(printf "%s\n%s" "${curl_conf}" "$1")
            shift
        else
            # We have an argument to an option: append a quoted version after whitespace
            curl_conf=$(printf "%s \"%s\"" "${curl_conf}" "$1")
            shift
        fi
    done
    shift  # Remove the final --
fi


# If the user forgot the -- after the curl options, checking the usage here will catch it. Also, we
# haven't yet created any files or directories, so this is a clean place to do the check.
if [ $# -lt 4 ]; then
    echo "Usage: $0 [opts] [-- curlopts --] <host> <outpath> <remote> <local> [...]" >&2
    echo "   Use --help for details" >&2
    exit 2
fi


# Obtain the base URL and output path from the first two arguments. Clean up to remove any trailing slashes.
base_url=$(echo "$1" | sed 's/\/*$//')
out_path=$(echo "$2" | sed 's/\/*$//')
[ -z "${out_path}" ] && out_path="/"


# Quick sanity check: be sure the base URL actually looks like a URL
if ! echo "${base_url}" | grep -q '^[A-Za-z0-9][A-Za-z0-9]*://'; then
    echo "Invalid URL format: $1" >&2
    exit 2
fi


# Check that the output directory exists and is writable
if [ -d "${out_path}" ]; then
    if [ ! -w "${out_path}" ]; then
        echo "Not writable: ${out_path}" >&2
        exit 1
    fi
else
    echo "Directory not found: ${out_path}" >&2
    exit 1
fi


# Done checking URL and output path; now verify that the remaining number of arguments is even
shift 2
num_params="$#"
if [ $(( num_params % 2 )) -ne 0 ]; then
    echo "Incorrect number of arguments: each remote needs local path" >&2
    exit 2
fi


# Create a temporary status directory if -s wasn't used
if [ -z "${status_output}" ]; then
    status_output=$(mktemp -d)
elif [ ! -d "${status_output}" ]; then
    echo "Directory not found: ${status_output}" >&2
    exit 1
fi
echo "${status_output}"


# Test write permissions by writing the PID of this script to the output directory
echo $$ > "${status_output}/wrapper_pid" || exit 1


# Now we need to create the rest of the curl configuration file, which will consist of pairs of --url
# and --output entries. Also figure out how many files we will transfer.
xfer_count=0
this_url=
while [ $# -gt 0 ]; do
    if [ -z "${this_url}" ]; then
        # We will write both the URL and output entry together in the configuration file, so save the url for now
        this_url="${base_url}/$1"
    else
        this_file="${out_path}/$1"
        curl_conf=$(printf "%s\n--url \"%s\"\n--output \"%s\"" "${curl_conf}" "${this_url}" "${this_file}")
        mkdir -p "${status_output}/${xfer_count}"
        echo "${this_url}" > "${status_output}/${xfer_count}/url"
        echo "${this_file}" > "${status_output}/${xfer_count}/destination"
        this_url=
        xfer_count=$(( xfer_count + 1 ))
    fi
    shift
done


# Write the base URL and total transfer count files
echo "${base_url}" > "${status_output}/base_url"
echo "${xfer_count}" > "${status_output}/total_transfers"


# If verbose mode is enabled, display the curl config on stderr
if [ -n "${verbose}" ]; then
    echo "---" >&2
    echo "${curl_conf}" >&2
    echo "---" >&2
fi


# Install signal handlers for use with curl
trap sighup HUP
trap sigint INT
trap sigquit QUIT
trap sigterm TERM
trap sigcont CONT
trap sigtstop TSTP


# Now we can finally run curl (in the background)
echo "${curl_conf}" | curl ${enable_config} -w '%{exitcode},%{http_code}\n' -f -K - \
    2>"${status_output}/progress.log" >"${status_output}/status_codes" &
curlpid=$!


# While curl runs, update the progress information every second, yielding between updates
while true; do
    ppid=$(ps -p "${curlpid}" -o ppid=)
    if [ -n "${ppid}" ]; then
        if [ "${ppid}" -eq "$$" ]; then
            update_progress
            sleep 1
        else
            # The curl process ID number has already been reused by something else, since we're no
            # longer its parent
            break
        fi
    else
        # curl has finished or died
        break
    fi
done


# Do a final progress update, in case we were asleep when curl finished
update_progress


# Get the exit status from curl and write it to the status directory
wait "${curlpid}"
status=$?
echo "${status}" > "${status_output}/result"


# Extract per-file status codes and HTTP response codes. Clean up any partially downloaded files.
index=0
while read -r line < "${status_output}/status_codes"; do
    file_status=$(echo "${line}" | awk -F ',' '{print $1}')
    http_code=$(echo "${line}" | awk -F ',' '{print $2}')

    echo "${file_status}" > "${status_output}/${index}/result"
    [ -n "${http_code}" ] && echo "${http_code}" > "${status_output}/${index}/http_code"

    if [ "${file_status}" -ne 0 ]; then
        out_path=$(cat "${status_output}/${index}/destination")
        rm -f "${out_path}"
    fi

    index=$(( index + 1 ))
done


# If the transfer was interrupted before all URLs were attempted, clean up any remaining output files.
while [ "${index}" -lt "${xfer_count}" ]; do
    out_path=$(cat "${status_output}/${index}/destination")
    if [ -f "${out_path}" ]; then
        echo "${status}" > "${status_output}/${index}/result"
        rm -f "${out_path}"
    else
        echo "-1" > "${status_output}/${index}/result"
    fi
done


# Report curl's exit status as our own
exit ${status}
