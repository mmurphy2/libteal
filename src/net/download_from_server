#!/bin/dash
#
# Downloads one or more files from a single server using curl(1). Download
# progress information is written to a temporary directory as the operation
# proceeds.
#
# Copyright 2022 Coastal Carolina University
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the “Software”), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.

# TODO refactoring in progress: not currently working

whatami=$(readlink -e "$0")
whereami=$(dirname "${whatami}")


usage() {
    cat << EOF
$0 [options] [-- curl_options --] <proto://host> <output_base> \\
             <remote_path> <local_filename> \\
             [[<remote_path> <local_filename>] ...]

Options:
    -e | --enable-config
        Enable reading the default curl configuration file(s). These are
        normally disabled, since the default configuration file locations
        are per-user instead of systemwide (see the man page for curl(1)).
        Providing this option suppresses the -q or --disable option, but
        later specifying -q or --disable in the curl_options will still
        prevent default configuration files from being loaded.
    -h | --help
        Show this help message and exit.
    -s <dir> | --status <dir>
        Use the specified directory for status files. Otherwise, a temporary
        directory is created with mktemp(1).
    -v | --verbose
        Display generated curl configuration on standard error.

Any option supported by curl(1) may be passed by surrounding the curl
options with two dashes (--) separated by spaces.

This program downloads one or more files from a single server, saving them
according to the specified <local_filename> in the <output_base> directory.
The base URL of the server is specified using <proto://host>. Each
<remote_path> is appended to the base directory to obtain the remote URL.
At the time of program invocation, <output_base> must already exist and be
writable by the program user.

Upon starting the operation, the status directory path is printed on
standard output. The status directory is organized in a hierarchy with
individual download data directories numbered starting from 0. At the top
level, status information consists of:

 base_url             The base URL from which files are downloaded
 current_transfer     The number of the current transfer
 progress.log         Raw progress output from curl
 result               Overall exit status, available when finished
 status_codes         Exit and HTTP response codes for each transfer
 total_transfers      The total number of files to be transferred

Each individual file transfer has its own status directory containing
information about the ongoing download:

 http_code            Response code for HTTP transfers
 percent              Integer percentage of the download completed
 remain               Time remaining in seconds
 result               Faux exit status?
 speed                Current transfer speed in bytes per second
 total                Total file size in bytes
 transferred          Total number of bytes downloaded so far

Note that percent, remain, and total require the server to provide a correct
content-length (or equivalent) at the start of the download. These values
therefore might not be available from some servers.
EOF
}


# Aborts the curl process (used for signal handling).
terminate_curl() {
    # We only need to terminate curl if it is running. The curl process is running if curlpid is non-empty,
    # the process with PID curlpid is found in the process table, and we are the parent of that process. This
    # extra parent check avoids an unlikely but possible condition where curl dies while this code's main loop
    # is asleep, and the PID number gets reused in the meantime.
    if [ -n "${curlpid}" ]; then
        local ppid=$(ps -p "${curlpid}" -o ppid=)
        if [ -n "${ppid}" ]; then
            if [ "${ppid}" -eq "$$" ]; then
                kill "${curlpid}"
            fi
        fi
    fi
}


update_progress() {
    cat "${status_output}/progress.log" | tr '\r' '\n' | \
        awk -f "${whereami}/download_from_server.awk" -v status_root="${status_output}"
}


status_output=
proxy=
enable_config="-q"
verbose=
while [ $# -gt 0 ]; do
    case "$1" in
        -e|--enable-config)
            enable_config=
            shift
        ;;
        -h|--help)
            usage
            exit 0
        ;;
        -s|--status)
            status_output="$2"
            shift 2
        ;;
        -v|--verbose)
            verbose="y"
            shift
        ;;
        *)
            break
        ;;
    esac
done


# Generate the curl configuration by appending any curl options
curl_conf="# generated curl configuration"
if [ x"$1" = x"--" ]; then
    shift
    while [ $# -gt 0 -a "x$1" != "--" ]; do
        if echo "$1" | grep -q '^-'; then
            # We have an option: start a new line and append the option
            curl_conf=$(printf "%s\n%s" "${curl_conf}" "$1")
            shift
        else
            # We have an argument to an option: append a quoted version after whitespace
            curl_conf=$(printf "%s \"%s\"" "${curl_conf}" "$1")
            shift
        fi
    done
    shift  # Remove the final --
fi


# If the user forgot the -- after the curl options, checking the usage here will catch it. Also, we
# haven't yet created any files or directories, so this is a clean place to do the check.
if [ $# -lt 4 ]; then
    echo "Usage: $0 [opts] [-- curlopts --] <host> <outpath> <remote> <local> [...]" >&2
    echo "   Use --help for details" >&2
    exit 2
fi


# Obtain the base URL and output path from the first two arguments. Clean up to remove any trailing slashes.
base_url=$(echo "$1" | sed 's/\/*$//')
out_path=$(echo "$2" | sed 's/\/*$//')
[ -z "${out_path}" ] && out_path="/"


# Quick sanity check: be sure the base URL actually looks like a URL
if ! echo "${base_url}" | grep -q '^[A-Za-z0-9][A-Za-z0-9]*://'; then
    echo "Invalid URL format: $1" >&2
    exit 2
fi


# Check that the output directory exists and is writable
if [ -d "${out_path}" ]; then
    if [ ! -w "${out_path}" ]; then
        echo "Not writable: ${out_path}" >&2
        exit 1
    fi
else
    echo "Directory not found: ${out_path}" >&2
    exit 1
fi


# Done checking URL and output path
shift 2


# Now we need to create the rest of the curl configuration file, which will consist of pairs of --url
# and --output entries. Also figure out how many files we will transfer.
xfer_count=0
this_url=
while [ $# -gt 0 ]; do
    if [ -z "${this_url}" ]; then
        # We will write both the URL and output entry together in the configuration file, so save the url for now
        this_url="${base_url}/$1"
    else
        this_file="${out_path}/$1"
        curl_conf=$(printf "%s\n--url \"%s\"\n--output \"%s\"" "${curl_conf}" "${this_url}" "${this_file}")
        this_url=
        xfer_count=$(( xfer_count + 1 ))
    fi
    shift
done


# If correct arguments have been given, this_url should be empty after generating the final configuration pair
if [ -n "${this_url}" ]; then
    echo "Incorrect number of arguments: each remote needs local path" >&2
    exit 2
fi


# Create a temporary status directory if -s wasn't used
if [ -z "${status_output}" ]; then
    status_output=$(mktemp -d)
elif [ ! -d "${status_output}" ]; then
    echo "Directory not found: ${status_output}" >&2
    exit 1
fi
echo "${status_output}"


# Test write permissions by writing the PID of this script to the output directory
echo $$ > "${status_output}/wrapper_pid" || exit 1


# Write the base URL and total transfer count files, then create the progress directories
echo "${base_url}" > "${status_output}/base_url"
echo "${xfer_count}" > "${status_output}/total_transfers"
x=0
while [ "${x}" -lt "${xfer_count}" ]; do
    mkdir -p "${status_output}/${x}"
    x=$((x + 1))
done


# If verbose mode is enabled, display the curl config on stderr
if [ -n "${verbose}" ]; then
    echo "---" >&2
    echo "${curl_conf}" >&2
    echo "---" >&2
fi


# Start curl in the background
echo "${curl_conf}" | curl ${enable_config} -w '%{exitcode},%{http_code}\n' -f -K - \
    2>"${status_output}/progress.log" >"${status_output}/status_codes" &
curlpid=$!


# While curl runs, update the progress information every second, yielding between updates
while true; do
    ppid=$(ps -p "${curlpid}" -o ppid=)
    if [ -n "${ppid}" ]; then
        if [ "${ppid}" -eq "$$" ]; then
            update_progress
            sleep 1
        else
            # The curl process ID number has already been reused by something else, since we're no
            # longer its parent
            break
        fi
    else
        # curl has finished or died
        break
    fi
done


# Do a final progress update, in case we were asleep when curl finished
update_progress


# Get the exit status from curl and write it to the status directory
wait "${curlpid}"
status=$?
echo "${status}" > "${status_output}/result"


# TODO: fix cleanup
# If the download failed, clean up the partial file
#if [ ${status} -ne 0 ]; then
#    rm -f "${out_path}"
#    exit 1
#fi


exit ${status}
